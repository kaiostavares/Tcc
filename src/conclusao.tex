\xchapter{Considerações Finais}{}

Este trabalho teve como objetivo investigar a aplicação de modelos de linguagem de larga escala como ferramenta de apoio à verificação automatizada da conformidade entre requisitos de software e sua respectiva implementação no código-fonte. A proposta visou explorar o potencial dessas tecnologias emergentes para atuar de forma complementar às práticas tradicionais de garantia da qualidade, fornecendo diagnósticos automatizados a partir da análise de artefatos reais de software.

Os resultados obtidos ao longo dos experimentos demonstraram, ainda que dentro de um escopo delimitado, evidências concretas da efetividade da abordagem adotada. Observou-se um desempenho satisfatório dos modelos na identificação de requisitos quando orientados por instruções bem estruturadas e semanticamente claras. A comparação entre versões de prompts evidenciou que pequenas variações na forma de comunicação influenciam de maneira significativa a acurácia das respostas, sendo que os melhores resultados foram associados ao uso de comandos mais objetivos e com escopo bem delimitado.

Em particular, os dados apontaram ganhos expressivos na métrica de acurácia estrita, que considera não apenas a correspondência entre a classificação da IA e a realidade do sistema, mas também a coerência explicativa da resposta fornecida. Houve, ainda, uma redução substancial da taxa de omissão em diversos cenários de análise, sugerindo que a abordagem é capaz de mitigar o risco de requisitos relevantes deixarem de ser analisados. Além disso, foi possível constatar que a performance dos modelos se mostrou superior quando a análise foi direcionada a módulos específicos do sistema, em contraste com avaliações aplicadas a repositórios extensos e heterogêneos, nos quais a fragmentação e a diversidade de arquivos dificultam a identificação precisa de implementações.

Além da acurácia estrita e da taxa de omissão, outras métricas de avaliação, como precisão, recall e F1-score, também foram fundamentais para uma compreensão mais abrangente do desempenho dos modelos. A precisão refletiu a capacidade dos agentes de evitar falsos positivos, enquanto o recall revelou o quanto os modelos foram eficazes em identificar requisitos realmente implementados. Já o F1-score, como métrica harmônica entre esses dois aspectos, demonstrou-se especialmente útil para avaliar o equilíbrio entre cautela e cobertura. A consideração conjunta dessas métricas reforça a robustez da abordagem proposta, ao permitir não apenas medir acertos, mas também qualificar a forma como esses acertos foram atingidos.

Contudo, é necessário reconhecer as limitações da presente investigação. Para uma avaliação mais conclusiva sobre a aplicabilidade prática da abordagem, seria indispensável expandir os testes para um conjunto mais amplo e variado de requisitos, bem como realizar experimentações em contextos reais de desenvolvimento, com acompanhamento em tempo real dos resultados. Além disso, a comparação sistemática entre as inferências produzidas pelos modelos e as avaliações realizadas por profissionais de qualidade de software permitiria estabelecer métricas de confiabilidade mais robustas. A inclusão de um espectro mais diverso de modelos de linguagem, com diferentes arquiteturas e capacidades, também contribuiria para validar a generalização dos resultados.

Dessa forma, embora os experimentos aqui relatados apresentem limitações quanto à escala, diversidade e profundidade da análise, os achados obtidos oferecem uma contribuição relevante ao demonstrar o potencial do uso de inteligência artificial na auditoria de conformidade entre requisitos e código-fonte. Os indícios observados reforçam a viabilidade de soluções baseadas em LLMs para apoiar a rastreabilidade, reduzir inconsistências e acelerar o ciclo de validação de funcionalidades em projetos de software.

Como desenvolvimento futuro, se vislumbra a integração desses agentes com protocolos como o Model Context Protocol (MCP), de modo a permitir ações automatizadas, como o envio de notificações, abertura de tarefas em sistemas de gestão de requisitos ou a geração de pull requests. Além disso, a adoção de técnicas baseadas em recuperação de conhecimento (RAG) poderá ampliar a capacidade de análise dos modelos em cenários nos quais a quantidade de arquivos ultrapassa os limites impostos pelas janelas de contexto, potencializando ainda mais sua aplicabilidade em ambientes de desenvolvimento reais e complexos.