@misc{braun2024,
  author       = {Braun, M. and others},
  title        = {Can ({A)I} have a word with you?: a taxonomy on the design dimensions of {AI} prompts},
  year         = {2024},
  url          = {https://research.cbs.dk/en/publications/can-ai-have-a-word-with-you-a-taxonomy-on-the-design-dimensions-o},
  note         = {Acesso em: 2 ago. 2025}
}

@article{desmond2024,
  author       = {Desmond, M. and Brachman, M.},
  title        = {Exploring prompt engineering practices in the enterprise},
  journal      = {arXiv preprint arXiv:2403.08950},
  year         = {2024},
  url          = {https://arxiv.org/abs/2403.08950},
  note         = {Acesso em: 29 ago. 2025}
}

@inproceedings{fan2018,
  author       = {Fan, A. and Lewis, M. and Dahl, G. B.},
  title        = {Hierarchical neural story generation},
  booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics},
  year         = {2018},
  url          = {https://aclanthology.org/P18-1082/},
  note         = {Acesso em: 2 ago. 2025}
}

@article{gunther2025,
  author       = {Günther, M. and others},
  title        = {Late chunking: contextual chunk embeddings using long-context embedding models},
  journal      = {arXiv preprint arXiv:2409.04701v3},
  year         = {2025},
  url          = {https://arxiv.org/abs/2409.04701},
  note         = {Acesso em: 27 jul. 2025}
}

@inproceedings{holtzman2020,
  author       = {Holtzman, A. and others},
  title        = {The curious case of neural text degeneration},
  booktitle    = {International Conference on Learning Representations ({ICLR})},
  year         = {2020},
  url          = {https://arxiv.org/abs/1904.09751},
  note         = {Acesso em: 29 jul. 2025}
}

@article{jelodar2025,
  author       = {Jelodar, H. and others},
  title        = {{Large Language Models} ({LLMs}) for source code analysis: applications, models and datasets},
  journal      = {arXiv preprint arXiv:2503.17502},
  year         = {2025},
  url          = {https://arxiv.org/abs/2503.17502},
  note         = {Acesso em: 28 jul. 2025}
}

@article{jin2024,
  author       = {Jin, H. and others},
  title        = {{LLM} maybe {LongLM}: self-extend {LLM} context window without tuning},
  journal      = {arXiv preprint arXiv:2401.01325v3},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.01325},
  note         = {Acesso em: 28 jul. 2025}
}

@misc{kin2023,
  author       = {Kin, Ho Young and Park, Youngok and Park, Jihee and Yin, Siyu and Kim, Juho},
  title        = {Understanding users’ dissatisfaction with {ChatGPT} responses: types, resolving tactics, and the effect of knowledge level},
  year         = {2023},
  url          = {https://arxiv.org/abs/2311.07434},
  note         = {Acesso em: 30 jul. 2025}
}

@article{lema2025,
  author       = {Le Ma, L. and others},
  title        = {A comprehensive survey on vector database: storage and retrieval technique, challenge},
  journal      = {arXiv preprint arXiv:2310.11703},
  year         = {2025},
  url          = {https://arxiv.org/abs/2310.11703},
  note         = {Acesso em: 28 jul. 2025}
}

@article{liu2023,
  author       = {Liu, J. and others},
  title        = {{RETA-LLM}: a retrieval-augmented large language model toolkit},
  journal      = {arXiv preprint arXiv:2306.05212},
  year         = {2023},
  url          = {https://arxiv.org/abs/2306.05212},
  note         = {Acesso em: 29 jul. 2025}
}

@article{melamed2023,
  author       = {Melamed, R. and others},
  title        = {Prompts have evil twins},
  journal      = {arXiv preprint arXiv:2311.07064},
  year         = {2023},
  url          = {https://arxiv.org/abs/2311.07064},
  note         = {Acesso em: 30 jul. 2025}
}

@misc{mcp2024,
  author       = {{Model Context Protocol}},
  title        = {Documentation},
  howpublished = {Disponível em: \url{https://modelcontextprotocol.io/overview}},
  year         = {2024},
  note         = {Acesso em: 2 ago. 2025}
}

@article{muennighoff2022,
  author       = {Muennighoff, N.},
  title        = {{SGPT}: {GPT} sentence embeddings for semantic search},
  journal      = {arXiv preprint arXiv:2202.08904},
  year         = {2022},
  url          = {https://arxiv.org/abs/2202.08904},
  note         = {Acesso em: 2 ago. 2025}
}

@article{nguyen2025,
  author       = {Nguyen, Minh Nhat and others},
  title        = {Turning up the heat: {Min-p} sampling for creative and coherent {LLM} outputs},
  journal      = {arXiv preprint arXiv:2407.01082v7},
  year         = {2025},
  url          = {https://arxiv.org/abs/2407.01082v7},
  note         = {Acesso em: 28 jul. 2025}
}

@misc{openai2023,
  author       = {{OpenAI}},
  title        = {{GPT-4} technical report},
  year         = {2023},
  howpublished = {Disponível em: \url{https://openai.com/index/gpt-4-research/}},
  note         = {Acesso em: 1 ago. 2025}
}

@article{raffel2020,
  author       = {Raffel, C. and others},
  title        = {Exploring the limits of transfer learning with a unified text-to-text transformer},
  journal      = {Journal of Machine Learning Research},
  year         = {2020},
  url          = {https://jmlr.org/papers/v21/20-074.html},
  note         = {Acesso em: 3 ago. 2025},
}

@inproceedings{renze2024,
  author       = {Renze, Matthew and Guven, Erhan},
  title        = {The effect of sampling temperature on problem solving in large language models},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP} 2024},
  year         = {2024},
  url          = {https://aclanthology.org/2024.findings-emnlp.432},
  note         = {Acesso em: 1 ago. 2025}
}

@book{sommerville2011,
  author       = {Sommerville, Ian},
  title        = {Engenharia de software},
  edition      = {9},
  address      = {São Paulo},
  publisher    = {Pearson Prentice Hall},
  year         = {2011}
}

@book{pressman2016,
  author       = {Pressman, Roger S.},
  title        = {Engenharia de Software: uma abordagem profissional},
  edition      = {7},
  address      = {Porto Alegre},
  publisher    = {AMGH},
  year         = {2016}
}

@article{vaswani2017,
  author       = {Vaswani, A. and Brain, G. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A. N. and Kaiser, {\L{}}. and Polosukhin, I.},
  title        = {Attention is all you need},
  journal      = {arXiv preprint arXiv:1706.03762},
  year         = {2017},
  url          = {https://arxiv.org/abs/1706.03762},
  note         = {Acesso em: 27 jul. 2025}
}

@article{wei2022,
  author       = {Wei, J. and others},
  title        = {Chain of thought prompting elicits reasoning in large language models},
  journal      = {arXiv preprint arXiv:2201.11903},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.11903},
  note         = {Acesso em: 30 jul. 2025}
}

@book{pmi2008,
  author       = {{Project Management Institute}},
  title        = {Um guia do conhecimento em gerenciamento de projetos ({Guia PMBOK{\textregistered}})},
  edition      = {4},
  address      = {Newtown Square, PA},
  publisher    = {Project Management Institute, Inc.},
  year         = {2008},
  isbn         = {978-1-933890-70-8}
}

@article{choi2020,
  author       = {Choi, R. Y. and others},
  title        = {Introduction to machine learning, neural networks, and deep learning},
  journal      = {Translational Vision Science \& Technology},
  volume       = {9},
  number       = {2},
  year         = {2020},
  note         = {Acesso em: 29 ago. 2025},
}

@misc{asimov2017,
  author       = {van Veen, Fjodor},
  title        = {The {Neural Network Zoo }},
  year         = {2017},
  howpublished = {Disponível em: \url{https://www.asimovinstitute.org/neural-network-zoo/}},
  note         = {Acesso em: 29 ago. 2025}
}

@inproceedings{bengio2007,
  author       = {Bengio, Y. and others},
  title        = {Greedy layer-wise training of deep networks},
  booktitle    = {Advances in Neural Information Processing Systems 19},
  year         = {2007},
  note         = {Acesso em: 29 ago. 2025},
}

@inproceedings{he2016,
  author       = {He, K. and others},
  title        = {Deep residual learning for image recognition},
  booktitle    = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
  year         = {2016},
  note         = {Acesso em: 29 ago. 2025},
}

@article{hochreiter1997,
  author       = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  title        = {Long short-term memory},
  journal      = {Neural Computation},
  volume       = {9},
  number       = {8},
  pages        = {1735--1780},
  year         = {1997},
  url          = {https://www.bioinf.jku.at/publications/older/2604.pdf},
  note         = {Acesso em: 30 ago. 2025}
}

@article{elman1990,
  author       = {Elman, J. L.},
  title        = {Finding structure in time},
  journal      = {Cognitive Science},
  volume       = {14},
  number       = {2},
  year         = {1990},
  note         = {Acesso em: 30 ago. 2025},
}

@article{chung2014,
  author       = {Chung, J. and others},
  title        = {Empirical evaluation of gated recurrent neural networks on sequence modeling},
  journal      = {arXiv preprint arXiv:1412.3555},
  year         = {2014},
  note         = {Acesso em: 30 ago. 2025},
  url          = {https://arxiv.org/abs/1412.3555}
}

@article{kingma2013,
  author       = {Kingma, D. P. and Welling, M.},
  title        = {Auto-encoding variational bayes},
  journal      = {arXiv preprint arXiv:1312.6114},
  year         = {2013},
  note         = {Acesso em: 30 ago. 2025},
  url          = {https://arxiv.org/abs/1312.6114}
}

@article{Ranzato1998,
  author       = {Ranzato, M. and others},
  title        = {Gradient-based learning applied to document recognition},
  journal      = {Proceedings of the {IEEE}},
  volume       = {86},
  number       = {11},
  pages        = {2278--2324},
  year         = {1998},
  note         = {Acesso em: 30 ago. 2025},
}

@article{goodfellow2014,
  author       = {Goodfellow, I. and others},
  title        = {Generative adversarial nets},
  journal      = {arXiv preprint arXiv:1406.2661},
  year         = {2014},
  note         = {Acesso em: 30 ago. 2025},
  url          = {https://arxiv.org/abs/1406.2661}
}

@article{ouyang2023,
  title        = {Training language models to follow instructions with human feedback},
  author       = {Ouyang, Long and others},
  journal      = {arXiv preprint arXiv:2203.02155},
  year         = {2022},
  note         = {Acesso em: 31 ago. 2025},
  url          = {https://arxiv.org/abs/2203.02155}
}

@article{liu2024hallucinations,
  title        = {Exploring and evaluating hallucinations in {LLM-powered} code generation},
  author       = {Liu, Fang and others},
  journal      = {arXiv preprint arXiv:2404.00971},
  year         = {2024},
  note         = {Acesso em: 31 ago. 2025},
  url          = {https://arxiv.org/abs/2404.00971}
}

@inproceedings{fan2023llmsw,
  title        = {Large language models for software engineering: survey and open problems},
  author       = {Fan, Angela and others},
  booktitle    = {{IEEE/ACM} International Conference on Software Engineering ({ICSE-FoSE})},
  year         = {2023},
  note         = {Acesso em: 31 ago. 2025},
}

@misc{ankit2024transformer,
  author       = {Ankit, Utkarsh and Whitfield, Brennan},
  title        = {Transformer neural networks: a step-by-step breakdown},
  year         = {2024},
  howpublished = {Disponível em: \url{https://builtin.com/artificial-intelligence/transformer-neural-network}},
  note         = {Acesso em: 30 ago. 2025}
}

@misc{raschka2025bigllm,
  author       = {Raschka, Sebastian},
  title        = {The big {LLM} architecture comparison},
  year         = {2025},
  howpublished = {Disponível em: \url{https://sebastianraschka.substack.com/p/the-big-llm-architecture-comparison}},
  note         = {Acesso em: 30 ago. 2025}
}

@article{shazeer2017outrageously,
  title        = {Outrageously large neural networks: the sparsely-gated mixture-of-experts layer},
  author       = {Shazeer, Noam and others},
  journal      = {arXiv preprint arXiv:1701.06538},
  year         = {2017},
  url          = {https://arxiv.org/abs/1701.06538},
  note         = {Acesso em: 31 ago. 2025}
}


@misc{ibm2024,
  author    = {IBM Corporation},
  title     = {What are AI agents?},
  year      = {2024},
  howpublished = {\url{https://www.ibm.com/think/topics/ai-agents}},
  note      = {Acesso em: 04 set. 2025}
}

@misc{microsoft2024,
  author    = {Microsoft},
  title     = {AI Agents: what they are and how they’ll change the way we work},
  year      = {2024},
  howpublished = {\url{https://news.microsoft.com/source/features/ai/ai-agents-what-they-are-and-how-theyll-change-the-way-we-work/}},
  note      = {Acesso em: 04 set. 2025}
}


@misc{awsAgent,
  author = {{Amazon Web Services}},
  title = {O que são agentes de IA?},
  year = {2024},
  url = {https://aws.amazon.com/pt/what-is/ai-agent/},
  note = {Acesso em: 04 set. 2025}
}

@misc{ibmAgent,
  author = {{IBM}},
  title = {What are AI agents?},
  year = {2024},
  url = {https://www.ibm.com/topics/ai-agents},
  note = {Acesso em: 04 set. 2025}
}

@article{sapkota2025,
  author = {Sapkota, Ranjan and Roumeliotis, Konstantinos I. and Karkee, Manoj},
  title = {AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges},
  journal = {arXiv preprint arXiv:2505.10468},
  year = {2025},
  note = {Acesso em: 04 set. 2025}
}